# Procesamiento de Lenguaje Natural

Repositorio con los desaf√≠os de la materia **Procesamiento de Lenguaje Natural** de la Especializaci√≥n en Inteligencia Artificial (FIUBA).

---

## Desaf√≠o 1: Vectorizaci√≥n de Texto y Clasificaci√≥n Na√Øve Bayes

üìÑ **Notebook:** `Desafio_1.ipynb`

### Descripci√≥n
Este desaf√≠o aborda la vectorizaci√≥n de documentos de texto y su clasificaci√≥n utilizando el dataset cl√°sico **20 Newsgroups**, que contiene aproximadamente 20,000 documentos distribuidos en 20 categor√≠as tem√°ticas diferentes.

### Objetivos
1. **Vectorizar documentos** y medir la similaridad entre ellos usando TF-IDF y similitud coseno.
2. **An√°lisis de similaridad**: Seleccionar 5 documentos al azar y encontrar los 5 m√°s similares, analizando si la similaridad tiene sentido seg√∫n el contenido y las etiquetas.
3. **Clasificaci√≥n Zero-Shot**: Implementar un modelo de clasificaci√≥n por prototipos asignando la clase del documento de entrenamiento m√°s similar.
4. **Entrenar modelos Na√Øve Bayes** (MultinomialNB y ComplementNB) optimizando hiperpar√°metros para maximizar el F1-score macro.
5. **Vectorizaci√≥n de palabras**: Transponer la matriz documento-t√©rmino para estudiar similaridad entre palabras.

### Soluci√≥n
- **Vectorizaci√≥n**: Se utiliz√≥ `TfidfVectorizer` de scikit-learn para convertir los documentos en vectores TF-IDF con un vocabulario de ~100,000 t√©rminos.
- **Similaridad**: Se aplic√≥ similitud coseno para encontrar documentos relacionados, observando que documentos de la misma categor√≠a (ej: religi√≥n, deportes) tienden a agruparse.
- **Zero-Shot**: Obtuvo un F1-score macro de ~50%, con mejor rendimiento en clases con vocabulario distintivo como `rec.sport.hockey` y `comp.windows.x`.
- **Na√Øve Bayes**: Se realiz√≥ b√∫squeda de hiperpar√°metros con GridSearchCV:
  - **MultinomialNB**: F1-score macro = 67.3%
  - **ComplementNB**: F1-score macro = 69.9% (mejor rendimiento)
- **An√°lisis de palabras**: La transposici√≥n de la matriz permiti√≥ encontrar relaciones sem√°nticas (ej: "moon" ‚Üí lunar, phases, satellite; "space" ‚Üí NASA, shuttle, SETI).

### Resultados Clave
| Modelo | F1-Score Macro | Accuracy |
|--------|:--------------:|:--------:|
| Zero-Shot | 50.5% | 50.9% |
| MultinomialNB | 67.3% | 69.7% |
| ComplementNB | 69.9% | 71.8% |

---

## Desaf√≠o 2: Custom Embeddings con Gensim

üìÑ **Notebook:** `Desafio_2.ipynb`

### Descripci√≥n
Este desaf√≠o consiste en crear embeddings de palabras personalizados utilizando la biblioteca **Gensim** y el texto completo de **"El Ingenioso Hidalgo Don Quijote de la Mancha"** obtenido de Project Gutenberg.

### Objetivos
1. **Crear vectores Word2Vec** propios basados en el corpus de Don Quijote.
2. **Explorar t√©rminos de inter√©s**: Buscar palabras m√°s similares y menos similares a t√©rminos clave de la obra.
3. **Reducci√≥n de dimensionalidad**: Aplicar t-SNE para proyectar los embeddings a 2 dimensiones.
4. **An√°lisis de clusters**: Identificar e interpretar grupos de palabras que se formen en la visualizaci√≥n.

### Soluci√≥n
- **Modelo Word2Vec**: Se entren√≥ un modelo Skipgram con los siguientes par√°metros:
  - `vector_size=300`: Dimensionalidad de los embeddings
  - `window=2`: Contexto de 2 palabras antes y despu√©s
  - `min_count=5`: Frecuencia m√≠nima para incluir palabras
  - `negative=20`: Negative sampling
  - 20 √©pocas de entrenamiento

- **Corpus**: 36,470 documentos (l√≠neas) con 5,509 palabras √∫nicas en el vocabulario.

- **An√°lisis de similaridad**:
  - *windmills* ‚Üí amadises, inhabitants, tombs, alcaldes
  - *dulcinea* ‚Üí del, dulcinea's, campo, toboso
  - *armour* ‚Üí shield, wrist, robe, doublet, fist
  - *king* ‚Üí lion, exploit, manuscript, marsilio

- **Visualizaci√≥n**: Se aplic√≥ t-SNE para reducir a 2D y se identificaron clusters tem√°ticos:
  - Grupos de personajes y lugares
  - Verbos modales y conectores
  - T√©rminos de caballer√≠a y aventura
  - N√∫meros y expresiones temporales

### Conclusiones
El modelo captura patrones ling√º√≠sticos y tem√°ticos consistentes con la narrativa de Don Quijote, agrupando t√©rminos que comparten contextos similares y mostrando cohesi√≥n sem√°ntica entre personajes, lugares y conceptos de la obra.

---

## Desaf√≠o 3: Modelo de Lenguaje con Tokenizaci√≥n por Caracteres

üìÑ **Notebook:** `Desafio_3.ipynb`

### Descripci√≥n
Implementaci√≥n de un **modelo de lenguaje a nivel de caracteres** utilizando redes neuronales recurrentes (RNN). Se entrena con el texto de **"La Odisea"** de Homero para generar texto nuevo.

### Objetivos
1. **Seleccionar un corpus** de texto para entrenar el modelo.
2. **Preprocesamiento**: Tokenizar por caracteres, estructurar el dataset y separar train/validaci√≥n.
3. **Proponer arquitecturas RNN**: Implementar y comparar SimpleRNN, LSTM y GRU.
4. **Generaci√≥n de texto**: Implementar estrategias de decodificaci√≥n (greedy search, beam search determin√≠stico y estoc√°stico) y analizar el efecto de la temperatura.

### Soluci√≥n
- **Corpus**: La Odisea de Homero (~681,000 caracteres, 58 caracteres √∫nicos en el vocabulario).
- **Preprocesamiento**: Secuencias de 100 caracteres, 90% entrenamiento / 10% validaci√≥n.
- **Arquitectura**: 2 capas RNN con 256 unidades, dropout 0.5, one-hot encoding.

**Modelos entrenados:**

| Arquitectura | Par√°metros | Perplejidad (Val) |
|--------------|:----------:|:-----------------:|
| SimpleRNN | 227,386 | 9.08 |
| LSTM | 863,290 | 4.33 |
| GRU | 652,858 | **4.11** |

**Estrategias de generaci√≥n:**
- **Greedy Search**: Determin√≠stico, r√°pido, pero tiende a loops.
- **Beam Search Determin√≠stico**: Mejor coherencia, explora m√∫ltiples hip√≥tesis.
- **Beam Search Estoc√°stico**: A√±ade diversidad controlada con temperatura.

**Efecto de la temperatura:**
- T=0.1: Texto coherente, menor variabilidad
- T=0.2: Introduce errores graduales
- T‚â•0.5: Texto incoherente

### Conclusiones
- **GRU** obtuvo el mejor rendimiento (PPL=4.11) con menos par√°metros que LSTM.
- La temperatura √≥ptima para este modelo est√° entre 0.1 y 0.2.
- Beam Search supera consistentemente a Greedy, evitando loops y produciendo texto m√°s natural.

---

## Desaf√≠o 4: Traductor LSTM Seq2Seq

üìÑ **Notebook:** `Desafio_4.ipynb`

### Descripci√≥n
Construcci√≥n de un **traductor autom√°tico ingl√©s-espa√±ol** utilizando una arquitectura **Sequence-to-Sequence (Seq2Seq)** con redes LSTM encoder-decoder, basado en el dataset del Tatoeba Project.

### Objetivos
1. **Extender el entrenamiento** a m√°s datos y tama√±os de secuencias mayores.
2. **Explorar el impacto de la cantidad de neuronas** en las capas recurrentes (64, 128, 256 unidades).
3. **Mostrar 5 ejemplos** de traducciones generadas.
4. **Extras**:
   - Utilizar embeddings pre-entrenados (GloVe) para el idioma de entrada.
   - Cambiar la estrategia de generaci√≥n implementando muestreo aleatorio y beam search estoc√°stico.

### Soluci√≥n
- **Dataset**: **118,964 pares de oraciones** ingl√©s-espa√±ol del Tatoeba Project (dataset completo).
- **Vocabulario**: 
  - Ingl√©s: **13,524 palabras** (entrada m√°x: 47 tokens, truncado a 16)
  - Espa√±ol: **26,341 palabras** (salida m√°x: 50 tokens, truncado a 18)
- **Embeddings**: GloVe pre-entrenados (50 dimensiones) para el encoder, embeddings entrenables para el decoder.
- **Tokens especiales**: `<sos>` (start of sequence), `<eos>` (end of sequence).

**Arquitectura:**
- **Encoder**: Embedding (GloVe) + LSTM que produce estados (h, c)
- **Decoder**: Embedding entrenable + LSTM + Dense con softmax

**Optimizaci√≥n de memoria:**

Para poder utilizar el dataset completo (~119K oraciones) se implementaron dos estrategias:

| Estrategia | Descripci√≥n | Ventaja |
|------------|-------------|---------|
| **DataGenerator** | Genera one-hot encoding por batch on-the-fly | Reduce uso de RAM significativamente |
| **create_tf_dataset** | Pipeline tf.data con prefetching y paralelizaci√≥n | **18-20% m√°s r√°pido** que DataGenerator |

**Impacto de la cantidad de neuronas:**

| Unidades LSTM | Train Accuracy | Val Accuracy | Observaciones |
|:-------------:|:--------------:|:------------:|---------------|
| 64 | 84.38% | 78.20% | Entrenamiento r√°pido, menor capacidad |
| 128 | 81.71% | 76.70% | Balance rendimiento/complejidad |
| **256** | **84.80%** | **77.26%** | **Mejor rendimiento (seleccionado)** |

**Estrategias de inferencia implementadas:**
- **Greedy**: Selecci√≥n del token m√°s probable en cada paso.
- **Beam Search estoc√°stico**: Exploraci√≥n de m√∫ltiples hip√≥tesis con muestreo probabil√≠stico y temperatura ajustable.

### Ejemplos de traducci√≥n

| Entrada (Ingl√©s) | Greedy | Beam Search | Evaluaci√≥n |
|------------------|--------|-------------|------------|
| "Happy new year!" | no te lo creer√° | ¬°feliz a√±o | ‚úÖ Beam Search superior |
| "I know what you mean" | s√© lo que me est√°s preguntando | s√© lo que te refieres | ‚úÖ Beam Search m√°s preciso |
| "Give me a break" | dame un respiro | dame un respiro | ‚úÖ Ambas correctas |
| "My mother say hi" | mi madre se ha ido | mi madre se cas√≥ | ‚ö†Ô∏è Identifica "madre" |
| "Don't push it" | no lo subestimes | - | ‚ö†Ô∏è Contexto correcto |

### Conclusiones

**Rendimiento del modelo:**
- El modelo con **256 unidades LSTM** obtuvo el mejor accuracy (84.80%) y fue seleccionado para inferencia.
- El uso de **EarlyStopping** (patience=3) previno overfitting severo a pesar de la mayor capacidad del modelo.
- **create_tf_dataset** result√≥ ~18-20% m√°s r√°pido que DataGenerator gracias al prefetching as√≠ncrono y one-hot encoding en GPU.

**Estrategias de generaci√≥n:**
- **Beam Search con temperatura baja (0.1-0.2)** generalmente produce mejores traducciones al explorar m√∫ltiples caminos.
- Hiperpar√°metros √≥ptimos: `beam_width=3-5` y `temperature=0.1-0.2`.

**Limitaciones identificadas:**
- Frases complejas o fuera del dominio del entrenamiento generan traducciones incorrectas.
- El modelo usa "Tom" como comod√≠n cuando no encuentra traducci√≥n adecuada (sesgo del dataset Tatoeba que contiene muchas oraciones con "Tom").
- Dificultad con expresiones idiom√°ticas y frases largas.

**Embeddings pre-entrenados:** GloVe mejor√≥ la representaci√≥n del encoder al capturar relaciones sem√°nticas del ingl√©s sin requerir entrenamiento adicional.

---

## Estructura del Repositorio

```
‚îú‚îÄ‚îÄ Desafio_1.ipynb          # Vectorizaci√≥n y Na√Øve Bayes
‚îú‚îÄ‚îÄ Desafio_2.ipynb          # Custom Embeddings con Gensim
‚îú‚îÄ‚îÄ Desafio_3.ipynb          # Modelo de Lenguaje RNN
‚îú‚îÄ‚îÄ Desafio_4.ipynb          # Traductor Seq2Seq
‚îú‚îÄ‚îÄ Desafio_4_pytorch.ipynb  # Versi√≥n alternativa en PyTorch
‚îú‚îÄ‚îÄ Desafio_4_dg.ipynb       # Versi√≥n con DataGenerator
‚îî‚îÄ‚îÄ README.md
```

---

## Tecnolog√≠as Utilizadas

- **Python 3.x**
- **TensorFlow / Keras** - Modelos de deep learning
- **scikit-learn** - Vectorizaci√≥n y clasificaci√≥n
- **Gensim** - Word2Vec embeddings
- **NumPy / Pandas** - Manipulaci√≥n de datos
- **Matplotlib / Seaborn** - Visualizaci√≥n
