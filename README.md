# Procesamiento de Lenguaje Natural

Repositorio con los desaf√≠os de la materia **Procesamiento de Lenguaje Natural** de la Especializaci√≥n en Inteligencia Artificial (FIUBA).

---

## Desaf√≠o 1: Vectorizaci√≥n de Texto y Clasificaci√≥n Na√Øve Bayes

üìÑ **Notebook:** `Desafio_1.ipynb`

### Descripci√≥n
Este desaf√≠o aborda la vectorizaci√≥n de documentos de texto y su clasificaci√≥n utilizando el dataset cl√°sico **20 Newsgroups**, que contiene aproximadamente 20,000 documentos distribuidos en 20 categor√≠as tem√°ticas diferentes.

### Objetivos
1. **Vectorizar documentos** y medir la similaridad entre ellos usando TF-IDF y similitud coseno.
2. **An√°lisis de similaridad**: Seleccionar 5 documentos al azar y encontrar los 5 m√°s similares, analizando si la similaridad tiene sentido seg√∫n el contenido y las etiquetas.
3. **Clasificaci√≥n Zero-Shot**: Implementar un modelo de clasificaci√≥n por prototipos asignando la clase del documento de entrenamiento m√°s similar.
4. **Entrenar modelos Na√Øve Bayes** (MultinomialNB y ComplementNB) optimizando hiperpar√°metros para maximizar el F1-score macro.
5. **Vectorizaci√≥n de palabras**: Transponer la matriz documento-t√©rmino para estudiar similaridad entre palabras.

### Soluci√≥n
- **Vectorizaci√≥n**: Se utiliz√≥ `TfidfVectorizer` de scikit-learn para convertir los documentos en vectores TF-IDF con un vocabulario de ~100,000 t√©rminos.
- **Similaridad**: Se aplic√≥ similitud coseno para encontrar documentos relacionados, observando que documentos de la misma categor√≠a (ej: religi√≥n, deportes) tienden a agruparse.
- **Zero-Shot**: Obtuvo un F1-score macro de ~50%, con mejor rendimiento en clases con vocabulario distintivo como `rec.sport.hockey` y `comp.windows.x`.
- **Na√Øve Bayes**: Se realiz√≥ b√∫squeda de hiperpar√°metros con GridSearchCV:
  - **MultinomialNB**: F1-score macro = 67.3%
  - **ComplementNB**: F1-score macro = 69.9% (mejor rendimiento)
- **An√°lisis de palabras**: La transposici√≥n de la matriz permiti√≥ encontrar relaciones sem√°nticas (ej: "moon" ‚Üí lunar, phases, satellite; "space" ‚Üí NASA, shuttle, SETI).

### Resultados Clave
| Modelo | F1-Score Macro | Accuracy |
|--------|:--------------:|:--------:|
| Zero-Shot | 50.5% | 50.9% |
| MultinomialNB | 67.3% | 69.7% |
| ComplementNB | 69.9% | 71.8% |

---

## Desaf√≠o 2: Custom Embeddings con Gensim

üìÑ **Notebook:** `Desafio_2.ipynb`

### Descripci√≥n
Este desaf√≠o consiste en crear embeddings de palabras personalizados utilizando la biblioteca **Gensim** y el texto completo de **"El Ingenioso Hidalgo Don Quijote de la Mancha"** obtenido de Project Gutenberg.

### Objetivos
1. **Crear vectores Word2Vec** propios basados en el corpus de Don Quijote.
2. **Explorar t√©rminos de inter√©s**: Buscar palabras m√°s similares y menos similares a t√©rminos clave de la obra.
3. **Reducci√≥n de dimensionalidad**: Aplicar t-SNE para proyectar los embeddings a 2 dimensiones.
4. **An√°lisis de clusters**: Identificar e interpretar grupos de palabras que se formen en la visualizaci√≥n.

### Soluci√≥n
- **Modelo Word2Vec**: Se entren√≥ un modelo Skipgram con los siguientes par√°metros:
  - `vector_size=300`: Dimensionalidad de los embeddings
  - `window=2`: Contexto de 2 palabras antes y despu√©s
  - `min_count=5`: Frecuencia m√≠nima para incluir palabras
  - `negative=20`: Negative sampling
  - 20 √©pocas de entrenamiento

- **Corpus**: 36,470 documentos (l√≠neas) con 5,509 palabras √∫nicas en el vocabulario.

- **An√°lisis de similaridad**:
  - *windmills* ‚Üí amadises, inhabitants, tombs, alcaldes
  - *dulcinea* ‚Üí del, dulcinea's, campo, toboso
  - *armour* ‚Üí shield, wrist, robe, doublet, fist
  - *king* ‚Üí lion, exploit, manuscript, marsilio

- **Visualizaci√≥n**: Se aplic√≥ t-SNE para reducir a 2D y se identificaron clusters tem√°ticos:
  - Grupos de personajes y lugares
  - Verbos modales y conectores
  - T√©rminos de caballer√≠a y aventura
  - N√∫meros y expresiones temporales

### Conclusiones
El modelo captura patrones ling√º√≠sticos y tem√°ticos consistentes con la narrativa de Don Quijote, agrupando t√©rminos que comparten contextos similares y mostrando cohesi√≥n sem√°ntica entre personajes, lugares y conceptos de la obra.

---

## Desaf√≠o 3: Modelo de Lenguaje con Tokenizaci√≥n por Caracteres

üìÑ **Notebook:** `Desafio_3.ipynb`

### Descripci√≥n
Implementaci√≥n de un **modelo de lenguaje a nivel de caracteres** utilizando redes neuronales recurrentes (RNN). Se entrena con el texto de **"La Odisea"** de Homero para generar texto nuevo.

### Objetivos
1. **Seleccionar un corpus** de texto para entrenar el modelo.
2. **Preprocesamiento**: Tokenizar por caracteres, estructurar el dataset y separar train/validaci√≥n.
3. **Proponer arquitecturas RNN**: Implementar y comparar SimpleRNN, LSTM y GRU.
4. **Generaci√≥n de texto**: Implementar estrategias de decodificaci√≥n (greedy search, beam search determin√≠stico y estoc√°stico) y analizar el efecto de la temperatura.

### Soluci√≥n
- **Corpus**: La Odisea de Homero (~681,000 caracteres, 58 caracteres √∫nicos en el vocabulario).
- **Preprocesamiento**: Secuencias de 100 caracteres, 90% entrenamiento / 10% validaci√≥n.
- **Arquitectura**: 2 capas RNN con 256 unidades, dropout 0.5, one-hot encoding.

**Modelos entrenados:**

| Arquitectura | Par√°metros | Perplejidad (Val) |
|--------------|:----------:|:-----------------:|
| SimpleRNN | 227,386 | 9.08 |
| LSTM | 863,290 | 4.33 |
| GRU | 652,858 | **4.11** |

**Estrategias de generaci√≥n:**
- **Greedy Search**: Determin√≠stico, r√°pido, pero tiende a loops.
- **Beam Search Determin√≠stico**: Mejor coherencia, explora m√∫ltiples hip√≥tesis.
- **Beam Search Estoc√°stico**: A√±ade diversidad controlada con temperatura.

**Efecto de la temperatura:**
- T=0.1: Texto coherente, menor variabilidad
- T=0.2: Introduce errores graduales
- T‚â•0.5: Texto incoherente

### Conclusiones
- **GRU** obtuvo el mejor rendimiento (PPL=4.11) con menos par√°metros que LSTM.
- La temperatura √≥ptima para este modelo est√° entre 0.1 y 0.2.
- Beam Search supera consistentemente a Greedy, evitando loops y produciendo texto m√°s natural.

---

## Desaf√≠o 4: Traductor LSTM Seq2Seq

üìÑ **Notebook:** `Desafio_4.ipynb`

### Descripci√≥n
Construcci√≥n de un **traductor autom√°tico ingl√©s-espa√±ol** utilizando una arquitectura **Sequence-to-Sequence (Seq2Seq)** con redes LSTM encoder-decoder, basado en el dataset del Tatoeba Project.

### Objetivos
1. **Extender el entrenamiento** a m√°s datos y tama√±os de secuencias mayores.
2. **Explorar el impacto de la cantidad de neuronas** en las capas recurrentes (64, 128, 256 unidades).
3. **Mostrar 5 ejemplos** de traducciones generadas.
4. **Extras**:
   - Utilizar embeddings pre-entrenados (GloVe) para el idioma de entrada.
   - Cambiar la estrategia de generaci√≥n implementando muestreo aleatorio y beam search estoc√°stico.

### Soluci√≥n
- **Dataset**: 10,000 pares de oraciones ingl√©s-espa√±ol del Tatoeba Project (de ~120,000 disponibles).
- **Vocabulario**: 
  - Ingl√©s: 4,948 palabras (entrada m√°x: 16 tokens)
  - Espa√±ol: 7,731 palabras (salida m√°x: 18 tokens)
- **Embeddings**: GloVe pre-entrenados (50 dimensiones) para el encoder, embeddings entrenables para el decoder.
- **Tokens especiales**: `<sos>` (start of sequence), `<eos>` (end of sequence).

**Arquitectura:**
- **Encoder**: Embedding (GloVe) + LSTM que produce estados (h, c)
- **Decoder**: Embedding entrenable + LSTM + Dense con softmax

**Impacto de la cantidad de neuronas:**

| Unidades LSTM | Val Accuracy | Val Loss | Observaciones |
|:-------------:|:------------:|:--------:|---------------|
| 64 | 72.6% | 1.69 | Entrenamiento r√°pido, menor capacidad |
| **128** | **73.3%** | **1.65** | Mejor balance rendimiento/complejidad |
| 256 | 74.2% | 1.60 | Mayor capacidad, m√°s lento |

**Estrategias de inferencia implementadas:**
- **Greedy**: Selecci√≥n del token m√°s probable en cada paso.
- **Muestreo aleatorio (sampling)**: Selecci√≥n estoc√°stica con temperatura ajustable.
- **Beam Search estoc√°stico**: Exploraci√≥n de m√∫ltiples hip√≥tesis con muestreo probabil√≠stico.

### Ejemplos de traducci√≥n

| # | Entrada (Ingl√©s) | Salida (Espa√±ol) |
|:-:|------------------|------------------|
| 1 | "My mother say hi" | "mi madre dice hola" |
| 2 | "Every end is a new beginning" | "cada fin es un nuevo comienzo" |
| 3 | "The best of both worlds" | "lo mejor de ambos mundos" |
| 4 | "I know what you mean" | "s√© lo que quieres decir" |
| 5 | "Give me a break" | "dame un descanso" |

### Conclusiones
- El modelo con **128 unidades LSTM** ofrece el mejor balance entre rendimiento y complejidad.
- **Impacto de las neuronas**: Aumentar de 64 a 256 unidades mejora el accuracy (~2%), pero incrementa significativamente el tiempo de entrenamiento.
- El accuracy alcanzado (~73%) es prometedor, aunque las traducciones a veces pierden precisi√≥n sem√°ntica en oraciones complejas.
- **Embeddings pre-entrenados**: GloVe mejor√≥ la representaci√≥n del encoder al capturar relaciones sem√°nticas del ingl√©s.
- **Estrategias de generaci√≥n**: Beam search estoc√°stico con temperatura baja (0.1-0.2) produjo traducciones m√°s variadas y naturales que greedy.
- **Limitaciones**: Por restricciones de RAM, solo se usaron 10,000 de los ~120,000 pares disponibles. Se recomienda usar DataGenerator para escalar.

---

## Estructura del Repositorio

```
‚îú‚îÄ‚îÄ Desafio_1.ipynb          # Vectorizaci√≥n y Na√Øve Bayes
‚îú‚îÄ‚îÄ Desafio_2.ipynb          # Custom Embeddings con Gensim
‚îú‚îÄ‚îÄ Desafio_3.ipynb          # Modelo de Lenguaje RNN
‚îú‚îÄ‚îÄ Desafio_4.ipynb          # Traductor Seq2Seq
‚îú‚îÄ‚îÄ Desafio_4_pytorch.ipynb  # Versi√≥n alternativa en PyTorch
‚îú‚îÄ‚îÄ Desafio_4_dg.ipynb       # Versi√≥n con DataGenerator
‚îî‚îÄ‚îÄ README.md
```

---

## Tecnolog√≠as Utilizadas

- **Python 3.x**
- **TensorFlow / Keras** - Modelos de deep learning
- **scikit-learn** - Vectorizaci√≥n y clasificaci√≥n
- **Gensim** - Word2Vec embeddings
- **NumPy / Pandas** - Manipulaci√≥n de datos
- **Matplotlib / Seaborn** - Visualizaci√≥n

---

## Autor

**Carla Esp√≠nola Hamm**  
Especializaci√≥n en Inteligencia Artificial - FIUBA
